# MOD√âLISER ET EXPLOITER DES CORPUS TEXTUELS

![banner](./img/banner.png)

### üî•üî•üî• seulement un corpus r√©duit est mis en ligne: 14 lettres sur les 267 du corpus originel
- le corpus complet, utilis√© pour l'atelier du 31, n'a pas encore √©t√© publi√© officiellement et n'est
  donc pas mis en ligne en l'√©tat
- les visualisations produites √† partir du corpus complet sont tout de m√™me visibles: 
  [`map_full`](./web/map_full.html) et [`network_full`](./web/network_full.html) : )

Supports pour la journ√©e d'atelier [Mod√©liser et exploiter des corpus textuels](https://odhn.ens.psl.eu/evenements/atelier-modeliser-et-exploiter-des-corpus-textuels), donn√©e avec L√©a Saint-Raymond √† l'ENS-PSL (31.03.2023). Cette journ√©e 
vise √† introduire aux bases de la mod√©lisation en XML-TEI, et surtout, aux m√©thodes d'analyse automatique,
de fouille de texte et de visualisation de corpus XML avec Python. 

La journ√©e est organis√©e en deux parties:
- le matin, on pr√©sente l'histoire du XML et de la TEI ainsi que les principes de base de la TEI
  √† partir d'un atelier d'encodage "√† la main".
- l'apr√®s-midi est consacr√© √† l'analyse outill√©e d'un corpus encod√© en XML avec Python (analyse de 
  r√©seaux, cartographie, reconnaissance d'entit√©s nomm√©es, API, manipulation et fouille de documents
  TEI)

---

## Cha√Æne de traitement, ou programme des hostilit√©s

- **`txt2xml`** (hors atelier): production du corpus, avec encodage automatique en XML-TEI du corpus
  Matsutaka en texte brut
- **`xmlanalysis`**: l'atelier en tant que tel. cha√Æne de traitement et d'enrichissement automatique
  du corpus en TEI.
  - extraction **d'informations g√©ographiques** depuis `Openstreetmap`, ajouts aux documents TEI d'un 
    `tei:settingDesc` documentant les lieux d'exp√©dition/destination de toutes les lettres du corpus.
    Librairies: `lxml`, `requests`
  - **extraction d'informations sur les entit√©s** (personnes, organisations) qui sont auteur.ice.s de lettres
    du corpus: extraction automatique, classification √† l'aide de SpaCy (r√©solution d'entit√©s nomm√©es),
    cr√©ation d'un `tei:particDesc` documentant ces auteur.ice.s et ajout de cet √©l√©ment aux documents TEI.
    Librairies: `lxml`, `spacy`
  - visualisation et **analyse du r√©seaux** d'exp√©diteur.ice.s / destinataires pr√©sent.e.s dans le corpus.
    Librairies: `pyvis`, `lxml`
  - **cartographie** des villes de r√©ception/exp√©dition des diff√©rentes lettres du corpus. Librairies 
    `lxml`, `folium`

---

## Utilisation en local

Le code et les notebooks peuvent √™tre ex√©cut√©s localement, √† l'aide de Jupyter Notebook ou en ex√©cutant
juste le code dans `src/`, sans les notebooks.

### Installation

(ps: je n'ai pu tester l'installation que sur Linux, il ne devrait pas y 
avoir de probl√®mes avec Mac ou Windows).

Git doit d√©j√† √™tre install√©. Ouvrir un terminal et entrer les commandes:

```bash
# cloner le d√©p√¥t
git clone https://github.com/paulhectork/cours_ens2023_xmltei.git
cd cours_ens2023_xmltei

# installer l'environnement virtuel
python3 -m venv env  # macos/linux
python3 -m venv .\env # windows

# sourcer l'environnement
source env/bin/activate  # macos/debian
env\Scripts\activate.bat # sur Windows. si ca ne marche pas, essayer: `env\Scripts\Activate.ps1` 

# installer les d√©pendances
pip install -r requirements.min.txt  # pour utiliser le code sans notebook
pip install -r requirements.txt      # pour utiliser le code avec notebook
```

### Utilisation

```bash
python src/txt2xml.py  # faire la transfo texte brut vers tei sous macos/linux
python src\txt2xml.py  # sous windows

python src/xmlanalysis.py  # faire la pipeline d'analyse sous linux/macos
python src\xmlanalysis.py  # windows

jupyter notebook  # lancer les notebooks
```

---

## Utilisation sur Google Colab

Le notebook est disponible √† [cette addresse](https://colab.research.google.com/drive/1x9fPUqPRTXmHtTcYaHgBN3Qzo3VRDN7L?usp=sharing)

Pour l'utiliser, il faut avoir la structure de dossier ci-dessous (je ne mets pas le notebook ici, 
puisque celui-ci est plac√© automatiquement par Google Colab). Tous les autres fichiers/dossiers sont 
cr√©√©s √† la demande par le notebook.

```
content/ (le dossier avec une ic√¥ne de folder, 4e ic√¥ne en partant du haut 
  |      tout √† gauche, en dessous du signe √©quation)
  |__xml/
      |__corpus_matsutaka.zip
```

Pour que le script puisse fonctionner, il faut que, apr√®s le d√©zippage, les
fichiers XML soient enregistr√©s dans `/content/xml/unzip/` (ce qui devrait √™tre 
g√©r√© automatiquement par le script).

---

## Structure du d√©p√¥t

```
/racine
  |__google_colab/  les notebooks utilisables en ligne sur Google Colab
  |
  |__jupyter_notebook/  les notebooks utilisables localement sur Jupyter Notebook
  |
  |__slides/  les slides de la matin√©e (pr√©sentation du XML-TEI)
  |
  |__src/  le code source utilis√© pour l'atelier
  |   |__txt2xml.py  cha√Æne d'encodage automatique du texte brut au XML-TEI (bonus!)
  |   |__xmlanalysis.py  cha√Æne de fouille des corpus XML-TEI. code source de
  |                      l'atelier √† proprement parler
  |
  |__txt/  dossier contenant les fichiers en texte brut encod√©s en TEI avec `src/txt2xml.py`
  |  
  |__web/  dossier de sortie de `xmlanalysis`
  |   |__json/  dossier contenant des geojson r√©cup√©r√©s de l'API nominatim contenant les infos
  |   |         g√©olocalis√©es sur le corpus
  |   |__network.html  la visualisation du r√©seau d'exp√©diteurices/destinataires du corpus Matsutaka
  |   |                produit automatiquement
  |   |__map.html  une visualisation cartographique des villes d'exp√©dition/destination des lettres
  |                du corpus Matsutaka
  |
  |__xml/  dossier contenant les fichiers XML-TEI produits avec `txt2xml.py` et utilis√©s comme source
  |   |    de l'atelier de l'apr√®s-midi
  |   |__schema/  dossier contenant le schema RNG de la TEI (publi√© sous license libre par le TEI consortium)
  |   |__template/  structure de base des documents TEI produits avec `txt2xml.py`
  |   |__unzip/  dossier contenant les fichiers XML d√©zipp√©s utilis√©s pour l'atelier de l'apr√®s-midi
  |   |__corpus_matsutaka.zip  archive zip de tous les fichiers XML
  |
  |__requirements.txt  les d√©pendances √† installer pour une utilisation sur Jupyter Notebook
  |__requirements.min.txt  les d√©pendances √† installer pour utiliser seulement le code python
                           (sans notebook) ou pour utiliser les notebooks Google Colab
```

--- 

## Debug et `pip`

Les mod√®les Spacy et les librairies utilis√©es sont tr√®s lourdes. J'ai rencontr√©
beaucoup de bugs pendant l'installation de d√©pendances, et il se peut que vous
aussi. Voil√† quelques solutions trouv√©es:

- dans un terminal, sous Ubuntu/Debian Linux (et peut-√™tre MacOS):
  - `pip install -U pip`: mettre √† jour `pip`
  - `rm -r $(find . -name __pycache__)`: supprimer les fichiers `*.pyc` qui peuvent 
    causer des erreurs: `EOFError: marshal data too short.` √† l'installation des
    d√©pendances.
- installer une version diff√©rente de Spacy ou de Tensorflow en fonction des sp√©cificit√©s
  de votre syst√®me (GPU ou non...). 
- ne pas installer les mod√®les `en_core_web_trf` et `fr_dep_news_trf`, tr√®s lourd,
  mais les mod√®les `en_core_web_sm` et `fr_core_news_sm`. Dans ce cas, il faut d√©sinstaller
  Spacy, supprimer tout l'environnement virtuel, et recommencer "√† la main" les installations
  (sans fichier de requirements, puisque dessus sont les mod√®les lourds et les d√©pendances 
  encore plus lourdes qui sont install√©es avec).

---

## Cr√©dits

### Production du corpus en texte brut 

L√©a Saint-Raymond. Dans l'attente d'une publication officielle, il n'est 
pas autoris√© d'utilis√© le corpus en dehors de l'atelier du 31 mars 2023.

### Code

Paul, Hector Kervegan, license libre GNU GPL 3.0. Ce d√©p√¥t contient le sch√©ma RNG
de la TEI
